{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "0f9ee467-cea4-48e8-9050-7a76ae1b6141"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 🚀 9c3e939 Python-3.8.13 torch-1.11.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11020MiB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete ✅ (16 CPUs, 31.0 GB RAM, 374.9/900.0 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR9ZbuQCH7FX",
        "outputId": "60647b99-e8d4-402c-f444-331bf6746da4"
      },
      "outputs": [],
      "source": [
        "cur_model_name = 'YOLOv5_Car/yolov5m_relu6'\n",
        "cur_model = f'/home/umit/models/{cur_model_name}/weights/best.pt'\n",
        "cur_img_dir = '/home/umit/git/image_models/dataset_51/datasets/OIDv6/validation/data'\n",
        "cur_project = f'/home/umit/expt/SD-680/{cur_model_name}'\n",
        "#!python detect.py --weights {cur_model} --img 640 --conf 0.25 --source {cur_img_dir} --project {cur_project} --save-txt --save-conf --save-crop --hide-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python detect.py --weights /home/umit/models/YOLOv5_Car/yolov5m_relu6/weights/best.pt --img 640 --conf 0.25 --source /home/umit/git/image_models/dataset_51/datasets/OIDv6/train/data --project /home/umit/expt/SD-680/YOLOv5_Car/yolov5m_relu6/train --save-txt --save-conf --save-crop\n"
          ]
        }
      ],
      "source": [
        "cur_set = 'train'\n",
        "cur_img_dir = f'/home/umit/git/image_models/dataset_51/datasets/OIDv6/{cur_set}/data'\n",
        "cur_project = f'/home/umit/expt/SD-680/{cur_model_name}/{cur_set}'\n",
        "cmd = f'python detect.py --weights {cur_model} --img 640 --conf 0.25 --source {cur_img_dir} --project {cur_project} --save-txt --save-conf --save-crop'\n",
        "print(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python detect.py --weights /home/umit/models/YOLOv5_LP/yolov5m_relu6/weights/best.pt --img 640 --conf 0.25 --source /home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/validation --project /home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/validation --save-txt --save-conf --save-crop\n"
          ]
        }
      ],
      "source": [
        "cur_model_name = 'YOLOv5_LP/yolov5m_relu6'\n",
        "cur_model = f'/home/umit/models/{cur_model_name}/weights/best.pt'\n",
        "cur_img_dir = '/home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/validation'\n",
        "cur_project = f'/home/umit/expt/SD-680/{cur_model_name}/validation'\n",
        "cmd = f'python detect.py --weights {cur_model} --img 640 --conf 0.25 --source {cur_img_dir} --project {cur_project} --save-txt --save-conf --save-crop'\n",
        "print(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python detect.py --weights /home/umit/models/YOLOv5_LP/yolov5m_relu6/weights/best.pt --img 640 --conf 0.25 --source /home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/train --project /home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/train --save-txt --save-conf --save-crop\n"
          ]
        }
      ],
      "source": [
        "cur_set = 'train'\n",
        "cur_img_dir = f'/home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/train'\n",
        "cur_project = f'/home/umit/expt/SD-680/{cur_model_name}/{cur_set}'\n",
        "cmd = f'python detect.py --weights {cur_model} --img 640 --conf 0.25 --source {cur_img_dir} --project {cur_project} --save-txt --save-conf --save-crop' # --hide-labels'\n",
        "print(cmd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'LP Confidences')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "# collect all confidences\n",
        "#cat /home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/train/exp2/labels/*.txt | awk '{print $6}' > /home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/train/exp2/labels/all.conf\n",
        "# load them\n",
        "train_conf = np.loadtxt('/home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/train/exp2/labels/all.conf')\n",
        "plt.hist(train_conf, 100)\n",
        "plt.grid()\n",
        "plt.title('LP Confidences')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Car Confidences')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_conf = np.loadtxt('/home/umit/expt/SD-680/YOLOv5_Car/yolov5m_relu6/train/exp/labels/all.conf')\n",
        "plt.hist(train_conf, 100)\n",
        "plt.grid()\n",
        "plt.title('Car Confidences')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge all detections to create a new set of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/umit/expt/SD-680/CAR_LP_merged/train/954eff13d5115067.txt\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "set_name = 'train'\n",
        "ref_img_dir = f'/home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/{set_name}'\n",
        "car_model_name = 'YOLOv5_Car/yolov5m_relu6'\n",
        "lp_model_name = 'YOLOv5_LP/yolov5m_relu6'\n",
        "lp_predictions = f'/home/umit/expt/SD-680/{lp_model_name}/{set_name}/exp/labels'\n",
        "car_predictions = f'/home/umit/expt/SD-680/{car_model_name}/{set_name}/exp/labels'\n",
        "merged_predictions = f'/home/umit/expt/SD-680/CAR_LP_merged/{set_name}'\n",
        "if not os.path.isdir(merged_predictions):\n",
        "    os.makedirs(merged_predictions)\n",
        "\n",
        "img_files = glob.glob(f'{ref_img_dir}/*.jpg')\n",
        "\n",
        "for img_file in img_files:\n",
        "    image_name = os.path.splitext(os.path.basename(img_file))[0]    \n",
        "    lp_pred_file = os.path.join(lp_predictions,image_name+'.txt')\n",
        "    car_pred_file = os.path.join(car_predictions,image_name+'.txt')\n",
        "    merged_pred_file = os.path.join(merged_predictions,image_name+'.txt') \n",
        "    # car is class 0, lp is class 1\n",
        "    with open(merged_pred_file, 'w') as outfile:\n",
        "        print(merged_pred_file)\n",
        "        if os.path.isfile(car_pred_file):\n",
        "            with open(car_pred_file) as infile:\n",
        "                outfile.write(infile.read())\n",
        "        if os.path.isfile(lp_pred_file):\n",
        "            with open(lp_pred_file) as infile:\n",
        "                for line in infile.readlines():\n",
        "                    aug_line = ['1'] + line.split()[1:]\n",
        "                    #aug_line = ' '.join(['1'.append(line.split()[1:]])\n",
        "                    outfile.write(' '.join(aug_line)+'\\n')\n",
        "                \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge existing transcriptions with LP detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3836085289.py, line 11)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    dataset_type = fo.types.  # for example\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# For any LP detection with > 0.5 confidence, we will add this to the labels and then do NMS on them.\n",
        "import fiftyone as fo\n",
        "\n",
        "# A name for the dataset\n",
        "name = \"my-dataset\"\n",
        "\n",
        "# The directory containing the dataset to import\n",
        "dataset_dir = \"/path/to/dataset\"\n",
        "\n",
        "# The type of the dataset being imported\n",
        "dataset_type = fo.types.  # for example\n",
        "\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_dir=dataset_dir,\n",
        "    dataset_type=dataset_type,\n",
        "    name=name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.ops import nms\n",
        "\n",
        "\n",
        "boxes = torch.tensor([[190,380,(190+300),(380+150)],\n",
        "                      [300,420,(300+150),(420+210)],\n",
        "                      [320,360,(320+200),(360+230)],\n",
        "\n",
        "                      [390,50,(390+300),(50+330)],\n",
        "                      [490,45,(490+200),(45+500)],\n",
        "                      [480,130,(480+150),(130+400)]], dtype=torch.float32)\n",
        "\n",
        "scores = torch.tensor([[0.90],[0.98],[0.82], [0.87],[0.98],[0.82]], dtype=torch.float32)\n",
        "\n",
        "nms(boxes = boxes, scores = scores, iou_threshold=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = plt.imread('index.jpg')\n",
        "\n",
        "# draw emtpy figure\n",
        "fig = plt.figure()\n",
        "\n",
        "# define axis\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# plot image\n",
        "plt.imshow(image)\n",
        "      \n",
        "# create rectangular patch\n",
        "#dog\n",
        "rect_0 = patches.Rectangle((190, 380), 300, 150, edgecolor='red', facecolor='none', linewidth=2)\n",
        "rect_1 = patches.Rectangle((300, 420), 150, 210, edgecolor='green', facecolor='none', linewidth=2)\n",
        "rect_2 = patches.Rectangle((320, 360), 200, 230, edgecolor='blue', facecolor='none', linewidth=2)\n",
        "\n",
        "#person\n",
        "rect_3 = patches.Rectangle((390, 50), 300, 330, edgecolor='red', facecolor='none', linewidth=2)\n",
        "rect_4 = patches.Rectangle((490, 45), 200, 500, edgecolor='green', facecolor='none', linewidth=2)\n",
        "rect_5 = patches.Rectangle((480, 130),150,400, edgecolor='blue', facecolor='none', linewidth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def yolo_to_pascal_voc(x_center, y_center, w, h,  image_w, image_h):\n",
        "    w = w * image_w\n",
        "    h = h * image_h\n",
        "    x1 = ((2 * x_center * image_w) - w)/2\n",
        "    y1 = ((2 * y_center * image_h) - h)/2\n",
        "    x2 = x1 + w\n",
        "    y2 = y1 + h\n",
        "    return [x1, y1, x2, y2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2, random, os\n",
        "def plot_one_box(x, image, color=None, label=None, line_thickness=None):\n",
        "    # Plots one bounding box on image img\n",
        "    tl = line_thickness or round(0.002 * (image.shape[0] + image.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(image, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(image, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(image, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "def draw_box_on_image(image_name, classes, colors, label_folder, raw_images_folder):\n",
        "    txt_path  = os.path.join(label_folder,'%s.txt'%(image_name))  #本次检测结果txt路径\n",
        "    if image_name == '.DS_Store':\n",
        "        return 0\n",
        "    image_path = os.path.join( raw_images_folder,'%s.jpg'%(image_name))  #本次原始图片jpg路径\n",
        "    \n",
        "    #save_file_path = os.path.join(save_images_folder,'%s.jpg'%(image_name)) #本次保存图片jpg路径\n",
        "    \n",
        "    # flag_people_or_car_data = 0  #变量 代表类别\n",
        "    source_file = open(txt_path)\n",
        "    image = cv2.imread(image_path)\n",
        "    try:\n",
        "        height, width, channels = image.shape\n",
        "    except:\n",
        "        print('no shape info.')\n",
        "        return 0\n",
        "\n",
        "    for line in source_file: #例遍 txt文件得每一行\n",
        "        staff = line.split() #对每行内容 通过以空格为分隔符对字符串进行切片\n",
        "        class_idx = int(staff[0])\n",
        "\n",
        "        x_center, y_center, w, h = float(staff[1])*width, float(staff[2])*height, float(staff[3])*width, float(staff[4])*height\n",
        "        x1 = round(x_center-w/2)\n",
        "        y1 = round(y_center-h/2)\n",
        "        x2 = round(x_center+w/2)\n",
        "        y2 = round(y_center+h/2)  \n",
        "        cur_label =   classes[class_idx] \n",
        "        if len(staff)>5:\n",
        "            cur_label = classes[class_idx]+'-%.2f'%float(staff[5])\n",
        "        plot_one_box([x1,y1,x2,y2], image, color=colors[class_idx], label=cur_label, line_thickness=None)\n",
        "\n",
        "        #cv2.imwrite(save_file_path,image) \n",
        "\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob, os\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "%matplotlib inline\n",
        "from time import sleep\n",
        "classes = ['CAR','LP']\n",
        "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(classes))]\n",
        "cur_img_dir = '/home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/train'\n",
        "cur_lbl_dir = '/home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/labels/train'\n",
        "car_det_dir = '/home/umit/expt/SD-680/YOLOv5_Car/yolov5m_relu6/train/exp/labels'\n",
        "lp_det_dir = '/home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/train/exp2/labels'\n",
        "all_files = glob.glob(f'{cur_img_dir}/*.jpg')\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "axim1 = ax1.imshow([0,0,0])\n",
        "axim2 = ax2.imshow([0,0,0])\n",
        "for file in all_files[:250]:\n",
        "    image_name = os.path.splitext(os.path.basename(file))[0]\n",
        "    im1 = draw_box_on_image(image_name, classes, colors, cur_lbl_dir, cur_img_dir)\n",
        "    #im_car, _ = draw_box_on_image(image_name, classes, colors, car_det_dir, cur_img_dir)\n",
        "    axim1.set_data(im1)\n",
        "\n",
        "    if os.path.isfile(f'{lp_det_dir}/{image_name}.txt'):\n",
        "        im_lp = draw_box_on_image(image_name, classes[1], colors[1], lp_det_dir, cur_img_dir)\n",
        "        #plt.figure(figsize=(10,10))\n",
        "        #ax2.imshow(im_lp)\n",
        "        axim2.set_data(im_lp)\n",
        "        #print(im1)\n",
        "    \n",
        "    plt.show()\n",
        "    fig.clear()\n",
        "    #ax1.clear()\n",
        "    #ax2.clear()\n",
        "    sleep(2.0)\n",
        "    #plt.pause(5.)\n",
        "    #plt.waitforbuttonpress(timeout=2)\n",
        "    #input(\"Enter\")\n",
        "    #plt.close()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Scalar value for argument 'color' is longer than 4\n>  - Scalar value for argument 'color' is longer than 4\n>  - argument for rectangle() given by name ('thickness') and position (4)\n>  - argument for rectangle() given by name ('thickness') and position (4)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m         x2 \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(x_center\u001b[39m+\u001b[39mw\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m         y2 \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(y_center\u001b[39m+\u001b[39mh\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)     \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m         plot_one_box([x1,y1,x2,y2], image, color\u001b[39m=\u001b[39;49mcolors, label\u001b[39m=\u001b[39;49mclasses[class_idx], line_thickness\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(image)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot(\u001b[39m122\u001b[39m)\n",
            "\u001b[1;32m/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb Cell 12\u001b[0m in \u001b[0;36mplot_one_box\u001b[0;34m(x, image, color, label, line_thickness)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m color \u001b[39m=\u001b[39m color \u001b[39mor\u001b[39;00m [random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m c1, c2 \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m(x[\u001b[39m0\u001b[39m]), \u001b[39mint\u001b[39m(x[\u001b[39m1\u001b[39m])), (\u001b[39mint\u001b[39m(x[\u001b[39m2\u001b[39m]), \u001b[39mint\u001b[39m(x[\u001b[39m3\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mrectangle(image, c1, c2, color, thickness\u001b[39m=\u001b[39;49mtl, lineType\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mLINE_AA)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m label:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmehrdad_desktop_ts/home/umit/git/image_models/yolov5-dg/car_lp_ds51.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     tf \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(tl \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# font thickness\u001b[39;00m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Scalar value for argument 'color' is longer than 4\n>  - Scalar value for argument 'color' is longer than 4\n>  - argument for rectangle() given by name ('thickness') and position (4)\n>  - argument for rectangle() given by name ('thickness') and position (4)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Now try to do merging with label files\n",
        "\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "import glob, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from utils.plots import Annotator\n",
        "\n",
        "\n",
        "classes = {0:'CAR',1:'LP'}\n",
        "colors = {0:0, 1:1}\n",
        "\n",
        "#colors = [random.randint(0, 255) for _ in range(len(segments))]\n",
        "line_thickness=4\n",
        "\n",
        "cur_img_dir = '/home/umit/git/image_models/dataset_51/exported_dataset/Car-Vehicle_registration_plate-/images/train'\n",
        "car_det_dir = '/home/umit/expt/SD-680/YOLOv5_Car/yolov5m_relu6/train/exp/labels'\n",
        "lp_det_dir = '/home/umit/expt/SD-680/YOLOv5_LP/yolov5m_relu6/train/exp2/labels'\n",
        "all_files = glob.glob(f'{cur_img_dir}/*.jpg')\n",
        "for file in all_files[3:10]:\n",
        "    image = plt.imread(file)\n",
        "    image_h, image_w, _ = image.shape\n",
        "\n",
        "    # draw emtpy figure\n",
        "    fig = plt.subplot(121)#figure()\n",
        "    # define axis\n",
        "    #ax = fig.add_axes([0, 0, 1, 1])\n",
        "    # plot image\n",
        "  \n",
        "    lbl_file = file.replace('images','labels').replace('.jpg','.txt')\n",
        "    lp_det_file = os.path.join(lp_det_dir,os.path.basename(lbl_file))\n",
        "    car_det_file = os.path.join(car_det_dir,os.path.basename(lbl_file))\n",
        "    with open(lbl_file) as file:\n",
        "        segments = [line.rstrip() for line in file]\n",
        "        colors = [random.randint(0, 255) for _ in range(len(segments))]\n",
        "        for segment in segments:\n",
        "            staff = segment.split()\n",
        "            class_idx = int(staff[0])\n",
        "            x_center, y_center, w, h = float(staff[1])*image_w, float(staff[2])*image_h, float(staff[3])*image_w, float(staff[4])*image_h\n",
        "            x1 = round(x_center-w/2)\n",
        "            y1 = round(y_center-h/2)\n",
        "            x2 = round(x_center+w/2)\n",
        "            y2 = round(y_center+h/2)     \n",
        "        \n",
        "            plot_one_box([x1,y1,x2,y2], image, color=colors, label=classes[class_idx], line_thickness=None)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    fig = plt.subplot(122)\n",
        "    # define axis\n",
        "    #ax = fig.add_axes([0, 0, 1, 1])\n",
        "    with open(lp_det_file) as file:\n",
        "        segments = [line.rstrip() for line in file]\n",
        "        colors = [random.randint(0, 255) for _ in range(len(segments))]\n",
        "        for segment in segments:\n",
        "            staff = segment.split()\n",
        "            class_idx = int(staff[0])+1\n",
        "            conf_lbl = classes[class_idx]+'%.2f'%float(staff[-1])\n",
        "            x_center, y_center, w, h = float(staff[1])*image_w, float(staff[2])*image_h, float(staff[3])*image_w, float(staff[4])*image_h\n",
        "            x1 = round(x_center-w/2)\n",
        "            y1 = round(y_center-h/2)\n",
        "            x2 = round(x_center+w/2)\n",
        "            y2 = round(y_center+h/2)     \n",
        "        \n",
        "            plot_one_box([x1,y1,x2,y2], image, color=colors, label=conf_lbl, line_thickness=None)\n",
        "    with open(car_det_file) as file:\n",
        "        segments = [line.rstrip() for line in file]\n",
        "        colors = [random.randint(0, 255) for _ in range(len(segments))]\n",
        "        for segment in segments:\n",
        "            staff = segment.split()\n",
        "            class_idx = int(staff[0])\n",
        "            conf_lbl = classes[class_idx]+'%.2f'%float(staff[-1])\n",
        "            x_center, y_center, w, h = float(staff[1])*image_w, float(staff[2])*image_h, float(staff[3])*image_w, float(staff[4])*image_h\n",
        "            x1 = round(x_center-w/2)\n",
        "            y1 = round(y_center-h/2)\n",
        "            x2 = round(x_center+w/2)\n",
        "            y2 = round(y_center+h/2)     \n",
        "        \n",
        "            plot_one_box([x1,y1,x2,y2], image, color=colors, label=conf_lbl, line_thickness=None)\n",
        "\n",
        "        \n",
        "    plt.imshow(image)\n",
        "'''\n",
        "            [cur_class, x_center, y_center, width, height]=segment.split()\n",
        "            boxes = yolo_to_pascal_voc(float(x_center), float(y_center), float(width), float(height), image_w, image_h)\n",
        "            annotator.box_label(boxes, label=str(cur_class))\n",
        "    im0 = annotator.result()\n",
        "    plt.imshow(im0)\n",
        "    plt.show()\n",
        "    print(segments)\n",
        "    with open(det_file) as file:\n",
        "        det_segments = [line.rstrip() for line in file]\n",
        "    print(det_segments)\n",
        "    #input(\"Press Enter\")\n",
        "    '''\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FGH0ZjkGjejy"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3026153189.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    rm -rf runs  # remove runs/\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# YOLOv5 CI\n",
        "%%shell\n",
        "rm -rf runs  # remove runs/\n",
        "m=yolov5n  # official weights\n",
        "b=runs/train/exp/weights/best  # best.pt checkpoint\n",
        "python train.py --imgsz 64 --batch 32 --weights $m.pt --cfg $m.yaml --epochs 1 --device 0  # train\n",
        "for d in 0 cpu; do  # devices\n",
        "  for w in $m $b; do  # weights\n",
        "    python val.py --imgsz 64 --batch 32 --weights $w.pt --device $d  # val\n",
        "    python detect.py --imgsz 64 --weights $w.pt --device $d  # detect\n",
        "  done\n",
        "done\n",
        "python hubconf.py --model $m  # hub\n",
        "python models/tf.py --weights $m.pt  # build TF model\n",
        "python models/yolo.py --cfg $m.yaml  # build PyTorch model\n",
        "python export.py --weights $m.pt --img 64 --include torchscript  # export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcKoSIK2WSzj"
      },
      "outputs": [],
      "source": [
        "# Reproduce\n",
        "for x in (f'yolov5{x}' for x in 'nsmlx'):\n",
        "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --task speed  # speed\n",
        "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gogI-kwi3Tye"
      },
      "outputs": [],
      "source": [
        "# Profile\n",
        "from utils.torch_utils import profile\n",
        "\n",
        "m1 = lambda x: x * torch.sigmoid(x)\n",
        "m2 = torch.nn.SiLU()\n",
        "results = profile(input=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSgFCAcMbk1R"
      },
      "outputs": [],
      "source": [
        "# VOC\n",
        "for b, m in zip([64, 64, 64, 32, 16], [f'yolov5{x}' for x in 'nsmlx']):  # batch, model\n",
        "  !python train.py --batch {b} --weights {m}.pt --data VOC.yaml --epochs 50 --img 512 --hyp hyp.VOC.yaml --project VOC --name {m} --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWGH7H6yakVl"
      },
      "outputs": [],
      "source": [
        "# Classification train\n",
        "for m in [*(f'yolov5{x}-cls.pt' for x in 'nsmlx'), 'resnet50.pt', 'resnet101.pt', 'efficientnet_b0.pt', 'efficientnet_b1.pt']:\n",
        "  for d in 'mnist', 'fashion-mnist', 'cifar10', 'cifar100', 'imagenette160', 'imagenette320', 'imagenette', 'imagewoof160', 'imagewoof320', 'imagewoof':\n",
        "    !python classify/train.py --model {m} --data {d} --epochs 10 --project YOLOv5-cls --name {m}-{d}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYgOiFNHZx-1"
      },
      "outputs": [],
      "source": [
        "# Classification val\n",
        "!bash data/scripts/get_imagenet.sh --val  # download ImageNet val split (6.3G - 50000 images)\n",
        "!python classify/val.py --weights yolov5m-cls.pt --data ../datasets/imagenet --img 224  # validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq4DPWGu0Bl1"
      },
      "outputs": [],
      "source": [
        "# Validate on COCO test. Zip results.json and submit to eval server at https://competitions.codalab.org/competitions/20794\n",
        "!bash data/scripts/get_coco.sh --test  # download COCO test-dev2017 (7G - 40000 images, test 20000)\n",
        "!python val.py --weights yolov5x.pt --data coco.yaml --img 640 --iou 0.65 --half --task test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTRwsvA9u7ln"
      },
      "outputs": [],
      "source": [
        "# TensorRT \n",
        "!pip install -U nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com  # install\n",
        "!python export.py --weights yolov5s.pt --include engine --imgsz 640 --device 0  # export\n",
        "!python detect.py --weights yolov5s.engine --imgsz 640 --device 0  # inference"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "YOLOv5 Tutorial",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('honk')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "15741134b8ddee0a711883ba84933d93251396c53ddbc5dddd85e39d42ad5fa7"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0856bea36ec148b68522ff9c9eb258d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ace3934ec6f4d36a1b3a9e086390926": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35e03ce5090346c9ae602891470fc555": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76879f6f2aa54637a7a07faeea2bd684",
            "max": 818322941,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ace3934ec6f4d36a1b3a9e086390926",
            "value": 818322941
          }
        },
        "574140e4c4bc48c9a171541a02cd0211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b913d755b34d638478e30705a2dde1",
            "placeholder": "​",
            "style": "IPY_MODEL_0856bea36ec148b68522ff9c9eb258d8",
            "value": "100%"
          }
        },
        "5966ba6e6f114d8c9d8d1d6b1bd4f4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b913d755b34d638478e30705a2dde1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65881db1db8a4e9c930fab9172d45143": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76879f6f2aa54637a7a07faeea2bd684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8caa3522fc4cbab31e13b5dfc7808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_574140e4c4bc48c9a171541a02cd0211",
              "IPY_MODEL_35e03ce5090346c9ae602891470fc555",
              "IPY_MODEL_c942c208e72d46568b476bb0f2d75496"
            ],
            "layout": "IPY_MODEL_65881db1db8a4e9c930fab9172d45143"
          }
        },
        "c942c208e72d46568b476bb0f2d75496": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b7a2243e0c4beca714d99dceec23d6",
            "placeholder": "​",
            "style": "IPY_MODEL_5966ba6e6f114d8c9d8d1d6b1bd4f4c7",
            "value": " 780M/780M [02:19&lt;00:00, 6.24MB/s]"
          }
        },
        "d6b7a2243e0c4beca714d99dceec23d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
